{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"`heudiconv` with ReproIn heuristic\"\n",
        "engine: jupyter\n",
        "jupyter: bash\n",
        "filters:\n",
        "  - collapse-output\n",
        "---\n",
        "\n",
        "## Installation\n",
        "\n",
        "Depending on your environment, paste the installation command here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# < replace with installation command >"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download the data\n",
        "\n",
        "Download the data by @nastase2020 from [Zenodo](https://doi.org/10.5281/zenodo.3677089).\n",
        "Note that the download make take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-fold": true
      },
      "source": [
        "wget https://zenodo.org/record/3677090/files/0219191_mystudy-0219-1114.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare the data\n",
        "\n",
        "Now we need to extract the downloaded archive.\n",
        "The following command extracts the `tar.gz` archive (`-x` extract, `-v` verbose, `-z` gzip, `-f` file)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-fold": true
      },
      "source": [
        "tar -xvzf 0219191_mystudy-0219-1114.tar.gz # <1>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect the raw data\n",
        "\n",
        "Let's navigate into the directory and see what's inside the dataset.\n",
        "Using `tree -L 2` we show the directory structure with a maximum depth of 2 levels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-fold": true
      },
      "source": [
        "tree -L 2 0219191_mystudy-0219-1114 # <1>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Decompress the data\n",
        "\n",
        "We need to decompress all gzipped DICOM files in the `dcm` directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-fold": true
      },
      "source": [
        "gunzip 0219191_mystudy-0219-1114/dcm/*.dcm.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run `heudiconv`\n",
        "\n",
        "Finally, we can run `heudiconv`!\n",
        "The following command converts DICOM files to BIDS format using the ReproIn heuristic for subject 01 and session 01.\n",
        "\n",
        "Here is an explanation for the flags and arguments:\n",
        "\n",
        "- `-f reproin` specifies the converter file to use\n",
        "- `--subject 01` specifies the subject\n",
        "- `--ses 01` specifies the subject\n",
        "- `--bids` is a flag for output into BIDS structure\n",
        "- `--files` or directories containing files to process\n",
        "- `--overwrite ` overwrites existing converted files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-fold": true
      },
      "source": [
        "heudiconv -f reproin --subject 01 --ses 01 --bids --files 0219191_mystudy-0219-1114/dcm --overwrite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspecting the BIDS dataset\n",
        "\n",
        "Let's inspect the new folder in more detail:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-fold": true
      },
      "source": [
        "tree -L 7 Norman"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validate the BIDS dataset\n",
        "\n",
        "That looks like a BIDS dataset!\n",
        "Let's check using the [BIDS Validator](https://bids-standard.github.io/bids-validator/):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-fold": true
      },
      "source": [
        "bids-validator-deno Norman/Mennen/5516_greenEyes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fixing a BIDS Dataset\n",
        "\n",
        "The BIDS Validator found several errors and issued a number of warnings.\n",
        "This means the dataset is not yet fully BIDS-compliant.\n",
        "You need to manually adjust the relevant files to fix these issues.\n",
        "Start by addressing the errors first.\n",
        "Errors make your dataset BIDS-incompatible and must be resolved for proper validation.\n",
        "Many [BIDS Apps](https://bids-apps.neuroimaging.io/) (like [fMRIPrep](https://fmriprep.org/en/stable/) and [MRIQC](https://mriqc.readthedocs.io/en/latest/)) require datasets to be error-free they can run.\n",
        "Warnings indicate that your dataset is technically BIDS-compliant, but improvements are recommended.\n",
        "You should try to resolve all warnings to ensure your dataset is robust and ready for downstream analysis.\n",
        "\n",
        "### Create a `.bidsignore` file\n",
        "\n",
        "Let the BIDS validator ignore `/sourcedata` and `.heudiconv`.\n",
        "To this end, we create a `.bidsignore` file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-fold": true
      },
      "source": [
        "touch Norman/Mennen/5516_greenEyes/.bidsignore\n",
        "echo \"/sourcedata\" > Norman/Mennen/5516_greenEyes/.bidsignore\n",
        "echo \".heudiconv\" >> Norman/Mennen/5516_greenEyes/.bidsignore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at the contents of the `.bidsignore` file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cat  Norman/Mennen/5516_greenEyes/.bidsignore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Remove data from the MRI loalizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-fold": true
      },
      "source": [
        "rm -rf Norman/Mennen/5516_greenEyes/sub-*/ses-*/*/*scout*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Remove repeated runs (resulting in duplications)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-fold": true
      },
      "source": [
        "rm -rf Norman/Mennen/5516_greenEyes/sub-*/ses-*/*/*_dup*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adjust the `scans.tsv` file:\n",
        "\n",
        "1. Import the `pandas` library for data manipulation.\n",
        "2. Load the `*scans.tsv` file into a DataFrame.\n",
        "3. Remove rows where the `'filename'` column contains `'_dup'` (duplicate runs).\n",
        "4. Further remove rows where `'filename'` contains `'scout'` (localizer scans).\n",
        "5. Save the cleaned DataFrame back to the original`*scans.tsv` file, overwriting it.\n",
        "\n",
        "```{python}\n",
        "import pandas as pd\n",
        "df = pd.read_csv('Norman/Mennen/5516_greenEyes/sub-01/ses-01/sub-01_ses-01_scans.tsv', sep='\\t')\n",
        "df_clean = df[~df['filename'].str.contains('_dup')]\n",
        "df_clean = df_clean[~df_clean['filename'].str.contains('scout')]\n",
        "df_clean.to_csv('Norman/Mennen/5516_greenEyes/sub-01/ses-01/sub-01_ses-01_scans.tsv', sep='\\t', index=False)\n",
        "```\n",
        "\n",
        "## Validate again\n",
        "\n",
        "Run the BIDS Validator repeatedly to verify that you resolved remaining errors and warnings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-fold": true
      },
      "source": [
        "bids-validator-deno Norman/Mennen/5516_greenEyes/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cool, no more errors!\n",
        "\n",
        "## What's next?\n",
        "\n",
        "Once you have a fully BIDS-compatible dataset, you can run [BIDS Apps](https://bids-apps.neuroimaging.io/) (like [fMRIPrep](https://fmriprep.org/en/stable/) and [MRIQC](https://mriqc.readthedocs.io/en/latest/)) and more!\n",
        "And you have a well-documented dataset that follows best community practices!\n",
        "Congrats!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "bash",
      "language": "bash",
      "display_name": "Bash",
      "path": "/usr/local/share/jupyter/kernels/bash"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}